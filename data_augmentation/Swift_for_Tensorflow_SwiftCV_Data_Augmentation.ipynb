{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Swift for Tensorflow - SwiftCV Data Augmentation",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "file_extension": ".swift",
      "mimetype": "text/x-swift",
      "name": "swift",
      "version": ""
    },
    "kernelspec": {
      "display_name": "Swift",
      "language": "swift",
      "name": "swift"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6S7MO1QXaVF",
        "colab_type": "text"
      },
      "source": [
        "# Swift for Tensorflow - SwiftCV Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gMKDv9AXtw4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "In this notebook, I will build an image classifier and train with data augmentation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3feKokVXX72h",
        "colab_type": "text"
      },
      "source": [
        "# Importing packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELd6snqWX8PB",
        "colab_type": "text"
      },
      "source": [
        "To use SwiftCV, first I need to download and install. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF2-HwcddiWk",
        "colab_type": "code",
        "outputId": "fac3ef48-acff-468b-b65b-379ee4b6035d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "// Install pre-compiled OpenCV 4.1.0 into Colab runtime\n",
        "%system curl -sL https://github.com/vvmnnnkv/opencv-colab/raw/master/opencv4.tar.gz | tar zxf - -C / && ldconfig /opt/opencv-4.1.0/lib/ && ln -s /opt/opencv-4.1.0/lib/pkgconfig/opencv4.pc /usr/lib/pkgconfig/opencv4.pc\n",
        "\n",
        "// Install SwiftCV package\n",
        "%install-location $cwd/swift-packages\n",
        "%install '.package(url: \"https://github.com/vvmnnnkv/SwiftCV.git\", .branch(\"master\"))' SwiftCV"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ln: failed to create symbolic link '/usr/lib/pkgconfig/opencv4.pc': File exists\n",
            "Installing packages:\n",
            "\t.package(url: \"https://github.com/vvmnnnkv/SwiftCV.git\", .branch(\"master\"))\n",
            "\t\tSwiftCV\n",
            "With SwiftPM flags: []\n",
            "Working in: /tmp/tmp2xcjh3u1/swift-install\n",
            "[1/2] Compiling jupyterInstalledPackages jupyterInstalledPackages.swift\n",
            "[2/3] Merging module jupyterInstalledPackages\n",
            "Initializing Swift...\n",
            "Installation complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaGgOzPQbGj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import TensorFlow\n",
        "import Foundation\n",
        "import Python\n",
        "import Time\n",
        "import SwiftCV\n",
        "import FoundationNetworking\n",
        "\n",
        "%include \"EnableIPythonDisplay.swift\"\n",
        "IPythonDisplay.shell.enable_matplotlib(\"inline\")\n",
        "let np = Python.import(\"numpy\")  // Make numpy available using np.\n",
        "let subprocess = Python.import(\"subprocess\")\n",
        "let plt = Python.import(\"matplotlib.pyplot\")\n",
        "let os = Python.import(\"os\")\n",
        "let glob = Python.import(\"glob\")\n",
        "let pil = Python.import(\"PIL\")\n",
        "let pilImageOps = Python.import(\"PIL.ImageOps\")\n",
        "let random = Python.import(\"random\")\n",
        "let sk = Python.import(\"skimage\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEIK0Qr6YpOw",
        "colab_type": "text"
      },
      "source": [
        "exercise, I had downloaded two class image dataset from Kaggle and used the data. To download the data, please use the following link: <a href=\"https://www.kaggle.com/c/dogs-vs-cats/data\" target=\"_blank\">Image Database</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf_vvLoESGWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "public extension String {\n",
        "    @discardableResult\n",
        "    func shell(_ args: String...) -> String {\n",
        "        let (task, pipe) = (Process(), Pipe())\n",
        "        task.executableURL = URL(fileURLWithPath: self)\n",
        "        (task.arguments, task.standardOutput) = (args, pipe)\n",
        "        do    { try task.run() }\n",
        "        catch { print(\"Unexpected error: \\(error).\") }\n",
        "\n",
        "        let data = pipe.fileHandleForReading.readDataToEndOfFile()\n",
        "        return String(data: data, encoding: String.Encoding.utf8) ?? \"\"\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7SwG2Ny9JHd",
        "colab_type": "code",
        "outputId": "dcea8a8d-4de2-4fd6-807f-606ab9ef5687",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(\"/bin/ls\".shell(\"-lh\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 12K\r\n",
            "drwxr-x--- 4  501 staff 4.0K Sep 23  2016 cats_and_dogs_filtered\r\n",
            "drwxr-xr-x 1 root root  4.0K Jan 13 16:38 sample_data\r\n",
            "drwxr-xr-x 4 root root  4.0K Jan 15 02:44 swift-packages\r\n",
            "\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZT6cUMweBCr",
        "colab_type": "text"
      },
      "source": [
        "Download the dataset from Github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpyLNoo3RDIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let command = \"wget -nv -O- https://github.com/anigasan/GCI/tree/master/data_augmentation/cats_and_dogs_filtered.tar.gz | tar xzf - -C .\"\n",
        "subprocess.call(command, shell: true)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvl9Lnce8H_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"/bin/ls/\".shell(\"-lh\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIEL_bnxZN6X",
        "colab_type": "text"
      },
      "source": [
        "### Understanding our data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqxHwJADZKVw",
        "colab_type": "text"
      },
      "source": [
        "We'll now assign variables with the proper file path for the training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXJjUDBOTNf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let catTrainList = glob.glob(\"cats_and_dogs_filtered/train/cats/*.jpg\")\n",
        "let dogTrainList = glob.glob(\"cats_and_dogs_filtered/train/dogs/*.jpg\")\n",
        "let trainList = glob.glob(\"cats_and_dogs_filtered/train/**/*.jpg\")\n",
        "\n",
        "let catTestList  = glob.glob(\"cats_and_dogs_filtered/validation/cats/*.jpg\")\n",
        "let dogTestList  = glob.glob(\"cats_and_dogs_filtered/validation/dogs/*.jpg\")\n",
        "let testList  = glob.glob(\"cats_and_dogs_filtered/validation/**/*.jpg\")\n",
        "\n",
        "for i in 0 ..< 5 {\n",
        "    np.random.shuffle(trainList)\n",
        "    np.random.shuffle(testList)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0v-OItU3ZOOO",
        "colab_type": "text"
      },
      "source": [
        "Let's look at how many cats and dogs images we have in our training and validation directory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pZdnDMKiybF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"total training cat images: \\(catTrainList.count)\")\n",
        "print(\"total training dog images: \\(dogTrainList.count)\")\n",
        "\n",
        "print(\"total validation cat images: \\(catTestList.count)\")\n",
        "print(\"total validation dog images: \\(dogTestList.count)\")\n",
        "print(\"--\")\n",
        "print(\"Total training images: \\(trainList.count)\")\n",
        "print(\"Total validation images: \\(testList.count)\")\n",
        "\n",
        "print(Python.type(trainList))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1RxO8dzdF2g",
        "colab_type": "text"
      },
      "source": [
        "### Visualizing Training images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFz4nx1LdGTZ",
        "colab_type": "text"
      },
      "source": [
        "We can visualize our training images by creating functions to plot images through their paths or tensors, and then plotting a few of them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCKdKItfmlep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "func plotImages(_ image: Tensor<Float>) {\n",
        "    let numpyImage = image.reshaped(to: [150, 150, 3]).makeNumpyArray()\n",
        "    plt.imshow(numpyImage)\n",
        "    plt.show()\n",
        "}\n",
        "\n",
        "func plotImages(fromPath path: String) {\n",
        "    let img = pil.Image.open(path)\n",
        "    let image = np.array(img) * (1.0 / 255)\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZRtJODkfxgf",
        "colab_type": "text"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE-K4a2Ql8tx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "func augmentedImage(path: String) -> Tensor<Float> {\n",
        "    \n",
        "    var cvImg = imread(path)\n",
        "    cvImg = cvtColor(cvImg, nil, ColorConversionCode.COLOR_BGR2RGB)\n",
        "    \n",
        "    if random.random() < 0.5 {\n",
        "       let rotMat = getRotationMatrix2D(Size(cvImg.cols / 2, cvImg.rows / 2), 20, 1)\n",
        "       cvImg = warpAffine(cvImg, nil, rotMat, Size(cvImg.cols, cvImg.rows))   \n",
        "    }\n",
        "    \n",
        "    if random.random() < 0.5 {\n",
        "        cvImg = transpose(cvImg,nil)\n",
        "    }\n",
        "    \n",
        "    if random.random() < 0.5 {\n",
        "      let h = Float(img.size[0])! / 4\n",
        "      let w = Float(img.size[1])! / 4\n",
        "      let cropBorder = Int(Python.min(h, w))\n",
        "  \n",
        "      cvImg = resize(cvImg, nil, Size(100, 50), 0, 0, InterpolationFlag.INTER_AREA)\n",
        "    }\n",
        "    \n",
        "    if random.random() < 0.5 {\n",
        "        cvImg = flip(cvImg, nil, FlipMode.HORIZONTAL)\n",
        "    }\n",
        "    \n",
        "    if random.random() < 0.5 {\n",
        "      cvImg = copyMakeBorder(cvImg, nil, 40, 40, 40, 40, BorderType.BORDER_CONSTANT, RGBA(0, 127, 0, 0))\n",
        "    }\n",
        "    \n",
        "   \n",
        "    var imgTens = Tensor<Float>(Tensor<UInt8>(cvMat: cvImg)!) / 255\n",
        "    let randTens = Tensor<Float>(randomNormal: imgTens.shape) * 0.1\n",
        "\n",
        "    \n",
        "    if random.random() < 0.5 {\n",
        "      imgTens += randTens\n",
        "      var image = imgTens.makeNumpyArray() // Add noise.\n",
        "    }\n",
        "\n",
        "    return imgTens\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl6vw_AcZd54",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ3OILUgZeqb",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JihjHwPi2Ch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "func resizedImage(fromPath: String, augmented: Bool) -> (Tensor<Float>, Int32) {\n",
        "    var img = pil.Image.open(fromPath)\n",
        "    var image = np.array(img, dtype: np.float32) * (1.0 / 255)\n",
        "    var imageTensor = Tensor<Float>(numpy: image)!\n",
        "    \n",
        "    if augmented {\n",
        "        imageTensor = augmentedImage(path: fromPath)\n",
        "    }\n",
        "    \n",
        "    imageTensor = imageTensor.expandingShape(at: 0)\n",
        "    imageTensor = Raw.resizeArea(images: imageTensor , size: [150, 150])\n",
        "    \n",
        "    let label: Int32 = fromPath.contains(\"dog.\") ? 0 : 1\n",
        "    \n",
        "    return (imageTensor, label)\n",
        "}\n",
        "\n",
        "func images(fromList: PythonObject, imageCount: Int, augmented: Bool) -> (image: Tensor<Float>, label: Tensor<Int32>) {\n",
        "    let batchFiles = fromList[0..<imageCount]\n",
        "    var labels: [Int32] = []\n",
        "    var x: Tensor<Float>\n",
        "    var y: Tensor<Int32>\n",
        "\n",
        "    // Load first image.\n",
        "    let path = String(batchFiles[0]) ?? \"\"\n",
        "    let data = resizedImage(fromPath: path, augmented: augmented)\n",
        "    x = data.0 \n",
        "    labels.append(data.1)\n",
        "\n",
        "    // Load rest of the images.\n",
        "    var numberOfFilesDone = 1\n",
        "    for file in batchFiles[1..<imageCount] {\n",
        "        let path = String(file) ?? \"\"\n",
        "        let data = resizedImage(fromPath: path, augmented: augmented)\n",
        "        let tensor = data.0\n",
        "        labels.append(data.1)\n",
        "        x = Tensor(concatenating: [x, tensor], alongAxis: 0)\n",
        "    }\n",
        "    y = Tensor<Int32>(labels)\n",
        "    return (x, y)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m427NXlc7Xw",
        "colab_type": "text"
      },
      "source": [
        "After defining our generators for images and labels, we will load those images and labels in tensor arrays, thereby creating our `testTensors`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xd8WDjGSBZYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let testTensors = images(fromList: testList, imageCount: testList.count, augmented: false)\n",
        "let testImageTensors = testTensors.0\n",
        "let testLabelTensors = testTensors.1\n",
        "print(testImageTensors.shape)\n",
        "print(testLabelTensors.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxjqzqP3doZn",
        "colab_type": "text"
      },
      "source": [
        "# Model Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye4j5sK9douT",
        "colab_type": "text"
      },
      "source": [
        "Build a model with 4 layers and with output of two classes (cats and dogs) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmaeXuZQUx2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "struct Classifier: Layer {\n",
        "    typealias Input = Tensor<Float>\n",
        "    typealias Output = Tensor<Float>\n",
        "\n",
        "    var conv1a = Conv2D<Float>(filterShape: (3, 3, 3, 32), activation: relu)\n",
        "    var pool1 = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
        "    \n",
        "    var conv1b = Conv2D<Float>(filterShape: (3, 3, 32, 64), activation: relu)\n",
        "    var pool2 = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
        "    \n",
        "    var conv1c = Conv2D<Float>(filterShape: (3, 3, 64, 128), activation: relu)\n",
        "    var pool3 = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
        "    \n",
        "    var conv1d = Conv2D<Float>(filterShape: (3, 3, 128, 128), activation: relu)\n",
        "    var pool4 = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
        "    \n",
        "    var dropout1a = Dropout<Float>(probability: 0.5)\n",
        "    var flatten = Flatten<Float>()\n",
        "    var layer1a = Dense<Float>(inputSize: 6272, outputSize: 512, activation: relu)\n",
        "    var layer1b = Dense<Float>(inputSize: 512, outputSize: 2, activation: softmax)\n",
        "\n",
        "    @differentiable\n",
        "    public func callAsFunction(_ input: Input) -> Output {\n",
        "        var convolved1 = input.sequenced(through: conv1a, pool1)\n",
        "        var convolved2 = convolved1.sequenced(through: conv1b, pool2)\n",
        "        var convolved3 = convolved2.sequenced(through: conv1c, pool3)\n",
        "        var convolved4 = convolved3.sequenced(through: conv1d, pool4)\n",
        "        return convolved4.sequenced(through: dropout1a, flatten, layer1a, layer1b)\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mE4Fv2cwdsWz",
        "colab_type": "text"
      },
      "source": [
        "### Compile the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsPxQTvwYmy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let tensor = Tensor<Float>(zeros: [1, 150, 150, 3])\n",
        "var classifier = Classifier()\n",
        "var optimizer = Adam(for: classifier)\n",
        "classifier(tensor).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fikBuWi3_a9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let epochCount = 100\n",
        "let batchSize = 100\n",
        "\n",
        "func minibatch<Scalar>(in x: Tensor<Scalar>, at index: Int) -> Tensor<Scalar> {\n",
        "    let start = index * batchSize\n",
        "    return x[start..<start + batchSize]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6oZ-9RKjGM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var trainingAccuracy: [Float] = []\n",
        "var validationAccuracy: [Float] = []\n",
        "var trainingLoss: [Float] = []\n",
        "var validationLoss: [Float] = []\n",
        "var epochsRange: [Int] = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq7RgKWbeaGZ",
        "colab_type": "text"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2xgoa_Aeai6",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJaSgWCgs90t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Training time again...\")\n",
        "\n",
        "struct Statistics {\n",
        "    var correctGuessCount: Int = 0\n",
        "    var totalGuessCount: Int = 0\n",
        "    var totalLoss: Float = 0\n",
        "}\n",
        "\n",
        "// The training loop.\n",
        "for epoch in 1...epochCount {\n",
        "    epochsRange.append(epoch)\n",
        "    var trainStats = Statistics()\n",
        "    var testStats = Statistics()\n",
        "    var ebegin = DispatchTime.now() // To compute time taken to epoch\n",
        "    print(\"Data Augmentation using SwiftCV for Epoch \\(epoch)\")\n",
        "    let trainTensors = images(fromList: trainList, imageCount: trainList.count, augmented: true)\n",
        "    let trainImageTensors = trainTensors.0\n",
        "    let trainLabelTensors = trainTensors.1\n",
        "    //print(\"Data Completed\")\n",
        "    \n",
        "    Context.local.learningPhase = .training\n",
        "    for i in 0..<Int(trainList.count) / batchSize {\n",
        "        let x = minibatch(in: trainImageTensors, at: i)\n",
        "        let y = minibatch(in: trainLabelTensors, at: i)\n",
        "        // Compute the gradient with respect to the model.\n",
        "        let 𝛁model = classifier.gradient { classifier -> Tensor<Float> in\n",
        "            let ŷ = classifier(x)\n",
        "            let correctPredictions = ŷ.argmax(squeezingAxis: 1) .== y\n",
        "            trainStats.correctGuessCount += Int(\n",
        "              Tensor<Int32>(correctPredictions).sum().scalarized())\n",
        "            trainStats.totalGuessCount += batchSize\n",
        "            let loss = softmaxCrossEntropy(logits: ŷ, labels: y)\n",
        "            trainStats.totalLoss += loss.scalarized()\n",
        "            return loss\n",
        "        }\n",
        "        // Update the model's differentiable variables along the gradient vector.\n",
        "        optimizer.update(&classifier, along: 𝛁model)\n",
        "    }\n",
        "\n",
        "    Context.local.learningPhase = .inference\n",
        "    for i in 0..<Int(testList.count) / batchSize {\n",
        "        let x = minibatch(in: testImageTensors, at: i)\n",
        "        let y = minibatch(in: testLabelTensors, at: i)\n",
        "        // Compute loss on test set.\n",
        "        let ŷ = classifier(x)\n",
        "        let correctPredictions = ŷ.argmax(squeezingAxis: 1) .== y\n",
        "        testStats.correctGuessCount += Int(Tensor<Int32>(correctPredictions).sum().scalarized())\n",
        "        testStats.totalGuessCount += batchSize\n",
        "        let loss = softmaxCrossEntropy(logits: ŷ, labels: y)\n",
        "        testStats.totalLoss += loss.scalarized()\n",
        "    }\n",
        "    \n",
        "    var eend = DispatchTime.now()\n",
        "    let trainAccuracy = Float(trainStats.correctGuessCount) / Float(trainStats.totalGuessCount)\n",
        "    let testAccuracy = Float(testStats.correctGuessCount) / Float(testStats.totalGuessCount)\n",
        "    \n",
        "    trainingAccuracy.append(trainAccuracy)\n",
        "    validationAccuracy.append(testAccuracy)\n",
        "    trainingLoss.append(trainStats.totalLoss)\n",
        "    validationLoss.append(testStats.totalLoss)\n",
        "    let nanoTime = eend.uptimeNanoseconds - ebegin.uptimeNanoseconds\n",
        "    let epochTime = Double(nanoTime) / 1_000_000_000  \n",
        "    \n",
        "    print(\"\"\"\n",
        "          [Epoch \\(epoch)] \\\n",
        "          Time Taken: \\(epochTime) \\\n",
        "          Training Loss: \\(trainStats.totalLoss), \\\n",
        "          Training Accuracy: \\(trainStats.correctGuessCount)/\\(trainStats.totalGuessCount) \\ \n",
        "          (\\(trainAccuracy)), \\\n",
        "          Test Loss: \\(testStats.totalLoss), \\\n",
        "          Test Accuracy: \\(testStats.correctGuessCount)/\\(testStats.totalGuessCount) \\\n",
        "          (\\(testAccuracy))\n",
        "          \"\"\")\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K2cWGKwe5hz",
        "colab_type": "text"
      },
      "source": [
        "### Visualizing results of the training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-YeHX65e6l0",
        "colab_type": "text"
      },
      "source": [
        "Let us plot accuracies to see if data augmentation is working or not!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmqhLD0UjLLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize: [12, 8])\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Training Accuracy(l) vs Validation Accuracy(o)\")\n",
        "plt.plot(epochsRange, trainingAccuracy)\n",
        "plt.plot(epochsRange, validationAccuracy)\n",
        "var loc = \"lower right\"\n",
        "plt.legend(loc)\n",
        "plt.title(\"Training and Validation Accuracy\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Training Loss(u) vs Validation Loss(p)\")\n",
        "plt.plot(epochsRange, trainingLoss)\n",
        "plt.plot(epochsRange, validationLoss)\n",
        "loc = \"upper right\"\n",
        "plt.legend(loc)\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV4iitDGbroi",
        "colab_type": "text"
      },
      "source": [
        "As we can see from the plots, training accuracy and validation accuracy are off by a much smaller margin than what we saw in Tutorial 5 and our model has achieved around **70%** accuracy on the validation set with a training accuracy of **74%** (depending on the number of epochs you trained for).\n",
        "\n",
        "This shows SwiftCV driven data augmentation is working and making training efficient with smaller datasets such as the one I had used in this notebook."
      ]
    }
  ]
}